/*
 * @Description: çˆ¬å–ç½‘é¡µå†…å®¹
 * @Author: Sunly
 * @Date: 2023-11-22 14:17:33
 */
import {
  Configuration,
  PlaywrightCrawler,
  purgeDefaultStorages,
} from "crawlee";
import type { Page } from "playwright";

import type { NextApiRequest, NextApiResponse } from "next";

export type ICrawlerParams = {
  target_urls: string[];
  match_urls: string[];
  max_pages: number;
  selector: string;
};

export type ICrawlerRes = {
  title: string;
  url: string;
  html: string;
};

export type ICrawlerData =
  | {
      success: true;
      data: ICrawlerRes[];
    }
  | {
      success: false;
      errMessage: string;
    };

function getHTML(page: Page, selector: string) {
  return page.evaluate((selector) => {
    const el: HTMLElement | null = document.querySelector(selector);
    return el?.innerText || "";
  }, selector);
}

function filterValidURLs(urlStr: string): string[] {
  const urls = urlStr.split(",");
  return urls.filter((url) => {
    url = url.trim();
    url =
      url.startsWith("https://") || url.startsWith("http://")
        ? url
        : `https://${url}`;
    try {
      new URL(url);
      return url;
    } catch (error) {
      return false;
    }
  });
}

export default async function handler(
  req: NextApiRequest,
  res: NextApiResponse<ICrawlerData>
) {
  console.log("=============req.query");
  console.log(
    "ğŸš€ ~ file: crawler-data.ts:63 ~ req.query.target_urls:",
    req.query.target_urls
  );
  const query = req.query as { [K in keyof ICrawlerParams]: string };
  console.log(
    "ğŸš€ ~ file: crawler-data.ts:63 ~ req.query.target_urls:1111",
    query.target_urls
  );
  let target_urls = filterValidURLs(query.target_urls);
  if (!target_urls.length) {
    res
      .status(400)
      .json({ success: false, errMessage: "è¯·ä¼ å…¥æœ‰æ•ˆçš„ç›®æ ‡ç½‘å€" });
  }
  let selector = query.selector.trim() || "body";
  let max_pages = Number(query.max_pages) > 50 ? 50 : Number(query.max_pages);
  let match_urls = filterValidURLs(query.match_urls);

  const crawlerData: ICrawlerRes[] = [];

  // åˆ›å»ºçˆ¬è™«
  const crawler = new PlaywrightCrawler({
    async requestHandler({ request, page, enqueueLinks, log }) {
      console.log("requestHandler", JSON.stringify(request, null, 2));
      const title = await page.title();
      log.info(`Page title: ${title}`);

      const html = await getHTML(page, selector);

      crawlerData.push({ title, url: request.loadedUrl || "", html });

      await enqueueLinks({ globs: match_urls });
    },

    maxRequestsPerCrawl: max_pages,
    maxConcurrency: 1,
  });

  // å¼€å§‹çˆ¬å–
  try {
    await crawler.run(target_urls);
  } catch (error) {
    res.status(500).json({
      success: false,
      errMessage: (error as Error).message || "è¯·æ±‚å¤±è´¥",
    });
  }

  // é‡ç½®å…¨å±€çŠ¶æ€
  Configuration.resetGlobalState();
  await purgeDefaultStorages();
  // å…³é—­çˆ¬è™«
  await crawler.teardown();

  res.status(200).json({ success: true, data: crawlerData });
}
